
    \begin{conf-abstract}[]
        {\textbf{Speech emotions detection and classification based on speech features using  deep neural network }}
        {\textit{Padmashree Desai$^{1}$}}
        {$^{1}$KLE Technological University}
        {\texttt{padmashri@kletech.ac.in}}
        \indexauthors{Desai!Padmashree}
        {Over the last decade, automatic speech emotion detection has been a major research area in the field of human-computer interaction. However, the current recognition accuracy has to be improved due to a lack of research on the fundamental temporal relationship of the speech waveform. Usually, speech includes calm, happy, sad, angry, fearful, surprise, and disgust emotions. Detecting and classifying has become a current research challenge. We developed a model to detect the emotion present in the speech data using Long-Short Term Memory(LSTM). The input audio is preprocessed through various techniques such as normalization, trimming, padding and noise reduction. The audio is then fed into the LSTM model to extract the features and detect the emotions. Feature extraction consists of Energy (Root Mean Square), Zero Crossing Rate and Mel Frequency Cepstral Coefficients (MFCCs). Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) and Toronto emotional speech set (TESS) combined datasets are used for testing and training the LSTM model. RAVDESS contains 7356 audio files including those of 24 proficient actors (12 male and 12 female). TESS contains 2800 audio files and emotions set on 200 target words spoken by two artists (aged between 26 to 64 years) and consists of eight emotions such as happiness, anger, fear, disgust, surprise, pleasant, sadness and neutral. Both datasets combined were used to train and test the LSTM model and eight emotions are detected which produces satisfactory outcomes. We obtained validation set and test set accuracy of 94.23\% and 97.47\% respectively for our system. The results are equated with the state-of-the-art methods which were found to be better. The proposed work can be improved by experimenting with  other deep learning techniques such as Recurrent Neural Network (RNN). }
    \end{conf-abstract}
        