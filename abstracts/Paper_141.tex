
    \begin{conf-abstract}[]
        {\textbf{SHAPRFs: SHapely Additive eXplanations based Random Forests algorithm for classification problems}}
        {\textit{Nishant Jain$^{1}$, Shipra Shukla$^{2}$}}
        {$^{1}$Manipal University Jaipur $\bullet$ $^{2}$Manipal University Jaipur}
        {\texttt{nishant.jain@jaipur.manipal.edu, shipra.shukla@jaipur.manipal.edu}}
        \indexauthors{Jain!Nishant, Shukla!Shipra}
        {"Tree-based ensemble algorithms" (TEAs) are widely used for classification and regression problems. However, existing TEAs lag behind the trade-off between TEA interpretability and achieving cutting-edge accuracy when applied to real-time applications. This paper proposes a new TEA for bridging the gap between real-time applications and the trade-off between TEA interpretability and cutting-edge accuracy. The proposed algorithm is based on the SHapley Additive exPlanations (SHAP) value, which is one of the most advanced co-operative game solutions for quantifying each feature's contribution to model prediction. As a result, we call our proposed algorithm the Shapely additive explanations based Random Forests algorithm (SHAPRFs). The proposed SHAPRFs compute the dominion of feature alliances using the SHAP value to determine the significance of each feature in the data set. Following suit, the SHAPRFs divide the features into two subsets based on the importance of each feature. Then it employs the Roulette wheel selection algorithm to generate decision trees (DTs) in the forest. Five benchmark data sets are used to test the SHAPRFs algorithm. The experimental results show that the proposed SHAPRFs outperform three well-known and benchmark classifiers by a significant margin, namely, Breiman random forest (BRF), deep forest, and support vector machines (SVM).}
    \end{conf-abstract}
        