
    \begin{conf-abstract}[]
        {\textbf{Deep Fusion-Net: A U-Net and CGAN-Based Approach for Salient Object Detection}}
        {\textit{Gayathri Dhara$^{1}$}}
        {$^{1}$SRM University-AP}
        {\texttt{gayathridhara@srmap.edu.in}}
        \indexauthors{Dhara!Gayathri}
        {Saliency detection, a critical task in the field of vision computing, with a goal to identify the visual prominent regions within an input image. The method of automated saliency identification has caught the interest of various application fields during the last decade.  A novel method is proposed for saliency detection through Conditional Generative Adversarial Networks with a pre-trained UNet model as the generator. The generated saliency maps are evaluated by the discriminator for authenticity and gives feedback to enhance the generator's ability to generate high-resolution saliency maps. By iteratively training the discriminator and generator networks, the model achieves improved performance in salient object detection. By combining the strengths of Conditional Generative Adversarial Networks (CGANs) and the UNet architecture, our goal is to improve the accuracy and enhance the quality. Once the U-Net model is trained and its weights are saved, we then integrated it into the CGAN framework for salient object detection. The U-Net will serve as the generator component of the CGAN, responsible for generating saliency maps for input images. The components of CGAN, are trained using adversarial learning to enhance the quality and realism of the generated saliency maps. Precision, recall, MAE and FÎ² score measurements are used to evaluate performance. Thorough experiments have conducted on three challenging saliency detection datasets, our model has demonstrated remarkable performance surpassing the latest models for saliency. Further, faster convergence is observed in our model due to the initialization of the CGAN's generator using pre-trained U-Net model weights.}
    \end{conf-abstract}
        