
    \begin{conf-abstract}[]
        {\textbf{CoViT-Net: A Pre-trained Hybrid Vision Transformer for COVID-19 Detection in CT-scans}}
        {\textit{Ankit Das$^{1}$, Debapriya Banik$^{2}$, Kaushiki Roy$^{3}$, Gordon K Chan$^{4}$, Debotosh Bhattacharjee$^{5}$}}
        {$^{1}$Amity University, Kolkata $\bullet$ $^{2}$Jadavpur University $\bullet$ $^{3}$Jadavpur University $\bullet$ $^{4}$University of Alberta $\bullet$ $^{5}$JU}
        {\texttt{ankitdas210@gmail.com, debu.cse88@gmail.com, kaushiki.cse@gmail.com, gkc@ualberta.ca, debotoshb@hotmail.com}}
        \indexauthors{Das!Ankit, Banik!Debapriya, Roy!Kaushiki, Chan!Gordon K, Bhattacharjee!Debotosh}
        {The coronavirus disease, COVID-19, that grasped the earth since 2019, has taken a serious toll on humanity. COVID-19 cases were spiking exponentially in densely populated regions, and the health infrastructure was challenged daily. As such, Artificial Intelligence (AI) had to step in to improvise medical imaging applications. One such use case was the classification of Computerized Tomography (CT) Scan images into COVID-infected and un-infected categories. Thus it would effectively classify a patient being either COVID Positive or Negative. Computer Vision (CV) algorithms manifest the potential to solve such image classification problems. In retrospect, deep learning-based architectures have been very productive. However, Vision Transformers (ViT) have taken over CV since its inception. In this study, we propose CoViT-Net: A pre-trained hybrid Vision Transformer architecture for detecting COVID-19 in CT scan images. Our proposed CoViT-Net has a unique architecture incorporating a ViT-S/16 feature extractor, pre-trained on the ImageNet21k dataset, and a modified MLP block with dense layers on top. CoViT-Net has thereby achieved a state-of-the-art accuracy score of 0.9638.}
    \end{conf-abstract}
        