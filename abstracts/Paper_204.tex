
    \begin{conf-abstract}[]
        {\textbf{Enhancing Graph-Based Representation Learning with Adversarial Policy Gradient: A Hyperparameter Analysis}}
        {\textit{Subhrasankar Chatterjee$^{1}$, Debasis Samanta$^{2}$}}
        {$^{1}$Indian Institute of Technology, Kharagpur $\bullet$ $^{2}$Indian Institute of Technology, Kharagpur}
        {\texttt{subhrasankarphd@iitkgp.ac.in, dsamanta@iitkgp.ac.in}}
        \indexauthors{Chatterjee!Subhrasankar, Samanta!Debasis}
        {Modeling the intricate neural mechanisms underlying human visual processing poses significant challenges. In recent years, graph-based representations have emerged as a promising approach to capturing inter-region relationships within the visual processing network. However, learning an optimal graph representation from limited data remains challenging, primarily due to the absence of ground truth to guide the learning process. This article analyzes a novel approach to graph-based representation generation using the Adversarial Policy Gradient framework. The adapted framework involves an adversarial game between the Policy Network and the Reward Network, iteratively improving the quality of the generated graph representation. By leveraging the strengths of both networks through this adversarial process, the approach yields refined and informative graph-based representations. Through extensive hyperparameter analysis, the study investigates the impact of various settings, including learning rates, network architectures, and number of episodes, on the performance of the Adversarial Policy Gradient approach. By examining the method's sensitivity to these hyperparameters, the article provides insights into the dynamics of graph-based representation learning and identifies optimal settings for high-quality representation spaces. The experimental results demonstrate the effectiveness of the proposed approach, highlighting its potential to overcome the challenges associated with learning graph representations from limited data. The findings shed light on the crucial role of hyperparameter selection in the success of the Adversarial Policy Gradient approach, providing researchers with valuable guidance in applying this methodology to various domains and tasks involving representation learning from graph-based data.}
    \end{conf-abstract}
        